---
title: "ST_02_Predictor Layers"
author: "Matthew Coghill"
format: html
editor: source
---

# South Thompson - Predictor Layer Generation

This script has very specific parameters required. First, all remote sensing data needs to be processed. For the South Thompson area, there are two main sources for this. First, a LAS file is required from processing RGB imagery through Pix4DMapper. This would have been originally acquired with the P1 camera. Next, multispectral images for each of those same flight areas needs to be collected and raster images of each band are required. Flights from this project have been named numerically, occasionally with a letter to indicate sub-flights for larger areas. An example flight name would be "5b". Each flight area should have both multispectral and RGB imagery taken from it, though some of the flight areas needed to be adjusted or constrained due to terrain limitations in some of the areas leading to inconsistent flight boundaries between RGB and multispectral flights. Despite this inconsistency, both RGB and multispectral imagery fully cover the entirety of the South Thompson project area, it just leads to slightly different processing pathways.

Overall, this script will tackle the predictor layer generation for the entire modelling process. Fundamentally, the DTM and CHM are first generated from the LAS files. The DTM is then used to derive climate based layers and terrain based layers. Climate layers include seasonal (summer) variables from 2023, which is the closest dataset that may be used at the time of writing. Terrain based variables include those that are included in the "basic terrain analysis" toolchain built into SAGA GIS, as well as a number of other useful terrain based variables. Finally, multispectral indices (e.g.: NDVI) are generated from the multispectral bands gathered from Pix4DMapper processing.

## Setup

The first step in this process involves loading the required packages. Some base options for this script are also set at this stage. Note that we require SAGA GIS version 9.6.1 or above for this script to proceed.

```{r init, include=FALSE}

ls <- c(
  "tidyverse", "terra", "lidR", "lasR", "Rsagacmd", "ClimateNAr",
  "RStoolbox", "future.apply"
)
invisible(suppressPackageStartupMessages(
  lapply(ls, library, character.only = TRUE)
))
rm(ls)

# Here, I set some memory options that allow for larger files to be stored in
# memory (allows for faster processing):
mem <- as.numeric(
  system("awk '/MemTotal/ {print $2}' /proc/meminfo", intern = TRUE)
)
terra_orig <- terraOptions(print = FALSE)
terraOptions(memfrac = 0.8, memmin = round((mem / 1024 / 1024) * (3 / 4)))

# Start SAGA GIS 9.6.1
saga_path <- "C:/SAGA-GIS/saga-9.6.1_x64/saga_cmd.exe"
saga <- saga_gis(saga_path, raster_format = "GeoTIFF", all_outputs = FALSE)

# Start over? Warning: deletes everything from main layer folder.
sanitize <- TRUE

# Set file access either over SFTP connection, Local LAN, or through the
# Synology Drive app (i.e.: "SFTP", "Local", "SynologyDrive", or whatever the
# folder name is for your Synology Drive app location)
serv_conn <- "Synology"

# Set raster resolution (coarse for testing, 0.5 for production)
rres <- 0.5

```

The files that we will be working with are located on the remote server. File access may be granted by contacting info\@aurorauav.com.

## File/folder initialization

Files are required off of the remote server, which then get processed locally in a temporary directory, and the final outputs are saved back to the remote server. Temporary files are removed as soon as they are able to be removed in order to save space on your local drives, though at times this script can produce \~100GB of temporary files. The directories for each step of the way are created at this time.

Additionally, this chunk will ensure that the KML/KMZ files (i.e.: flight boundaries) that are being used are meant for either the RGB or multispectral (MS) images being processed. This is based on file naming and file locations. For example, a given flight area might have both MS and RGB files within that directory, and a single KML file in that same directory would indicate that they share the same flight area.

```{r Directories, include=FALSE}

# Determine server directory method (change username if using SFTP connection)
if (serv_conn == "SFTP") {
  user <- "mcoghill"
  serv <- paste0("//", user, "@aurorauav.synology.me/Cheatgrass")
} else if (serv_conn == "Local") {
  serv <- "//AuroraNAS/Cheatgrass"
} else if (serv_conn == "Synology") {
  serv <- file.path(Sys.getenv("USERPROFILE"), "SynologyDrive/Cheatgrass")
} else {
  serv <- serv_conn
}

# Initialize directories
proj <- "South Thompson"
proc_dir <- file.path(serv, "Processed Imagery", proj)
layr_dir <- file.path(serv, "Modelling/Layers", proj)
tile_dir <- file.path(tempdir(), "01_LAS")
dtm_dir <- file.path(tempdir(), "02_DTM")
clm_dir <- file.path(tempdir(), "03_Climate")
ms_dir <- file.path(tempdir(), "04_Multispectral")
if (dir.exists(layr_dir) && sanitize) unlink(layr_dir, recursive = TRUE)
dir.create(layr_dir, showWarnings = FALSE)
invisible(
  sapply(c(tile_dir, dtm_dir, clm_dir, ms_dir),
    dir.create,
    showWarnings = FALSE
  )
)

# Each folder with a KMZ file will be used to process LAS files (i.e.: all RGB
# based projects) or multispectral files (i.e.: reflectance images).
kmz_files <- list.files(
  proc_dir,
  pattern = ".kmz$|.kml$", full.names = TRUE, recursive = TRUE
)
kmz_files_noext <- gsub(".kml$|.kmz$", "", kmz_files)
kmz_files <- kmz_files[!duplicated(kmz_files_noext)]
rgb_las_files <- list.files(
  proc_dir,
  pattern = "group1_densified_point_cloud.las$",
  full.names = TRUE, recursive = TRUE
)
refl_dirs <- dir(
  proc_dir,
  pattern = "Reflectance$", full.names = TRUE, recursive = TRUE,
  include.dirs = TRUE
)

# Filter RGB LAS files and MS dirs based on KMZ file presence
rgb_las_files <- rgb_las_files[dirname(rgb_las_files) %in% dirname(kmz_files)]
refl_dirs <- refl_dirs[dirname(refl_dirs) %in% dirname(kmz_files)]

# Unzip KMZ to KML
flights <- do.call(c, lapply(kmz_files, function(x) {
  if (endsWith(x, "kmz")) {
    kml_id <- grep(".kml$", unzip(x, list = TRUE)[, "Name"], value = TRUE)
    kml <- file.path(dirname(x), sub(".kmz$", ".kml", basename(x)))
    unzip(x, files = kml_id, exdir = dirname(x))
    file.rename(file.path(dirname(x), kml_id), kml)
  } else {
    kml <- x
  }
  return(kml)
}))

# Subset kmz/kml files
kml_rgb <- flights[dirname(flights) %in% dirname(rgb_las_files)]
kml_rgb <- kml_rgb[!endsWith(kml_rgb, "_MS.kml")]
kml_ms <- flights[dirname(flights) %in% dirname(refl_dirs)]
kml_ms <- kml_ms[!endsWith(kml_ms, "_RGB.kml")]

# Filter RGB LAS files and MS dirs based on KML file presence and names
rgb_las_files <- rgb_las_files[dirname(rgb_las_files) %in% dirname(kml_rgb)]
refl_dirs <- refl_dirs[dirname(refl_dirs) %in% dirname(kml_ms)]
rgb_df <- data.frame(rgb = rgb_las_files) %>%
  rowwise() %>%
  mutate(kml = kml_rgb[which(dirname(kml_rgb) == dirname(rgb))]) %>%
  ungroup() %>%
  mutate(flight = sapply(strsplit(basename(rgb), "_"), "[[", 1))
ms_df <- data.frame(ms = refl_dirs) %>%
  rowwise() %>%
  mutate(kml = kml_ms[which(dirname(kml_ms) == dirname(ms))]) %>%
  ungroup() %>%
  mutate(flight = sapply(strsplit(basename(dirname(ms)), "_"), "[[", 1))

# Initialize final grid frame
aoi <- suppressWarnings(vect(paste0(proj, "_AOI.kml"))) %>%
  project("EPSG:3153")
aoi_ext <- ext(
  plyr::round_any(xmin(aoi), 25, floor),
  plyr::round_any(xmax(aoi), 25, ceiling),
  plyr::round_any(ymin(aoi), 25, floor),
  plyr::round_any(ymax(aoi), 25, ceiling)
)
aoi_r <- rast(aoi_ext, res = rres, crs = terra::crs(aoi), vals = NA)

```

## LAS to DTM and CHM

Each flight area contains its own LAS file. For each of these LAS files we first have to split the single large LAS file into several smaller tiles (accomplished in the `lidR` package). Next, use the `lasR` package to clean the LAS tiles and generate the DTM/DEM and CHM. We get to make use of the "pipeline" functionality within the `lasR` package, where multiple functions are strung together by tying together inputs and outputs to efficiently produce desired products (e.g.: DTM). Outputs can be stored in RAM, offering much quicker processing to get to an output.

Once a DTM and CHM have been created for a given flight area, mask those layers to the shape of the flight areas provided. These smaller DTM files will be used for processing later in the `ClimateNAr` package because it is more efficient to generate the climate variables in this manner compared to generating climate variables from a single large mosaicked DTM.

```{r LAS_processing, include=FALSE}

set_lidr_threads(0)
las_proc <- lapply(seq_len(nrow(rgb_df)), function(x) {
  # Set some file parameters/input/output paths
  y <- pull(rgb_df, rgb)[x]
  kml_file <- pull(rgb_df, kml)[x]
  tile_out <- file.path(tile_dir, strsplit(basename(dirname(y)), "_")[[1]][1])
  dir.create(tile_out, showWarnings = FALSE)
  dtm_raw_out <- file.path(
    dtm_dir, paste0(strsplit(basename(dirname(y)), "_")[[1]][1], "_DTM_raw.tif")
  )
  chm_raw_out <- gsub("_DTM_raw.tif", "_CHM_raw.tif", dtm_raw_out)
  dtm_out <- gsub("_DTM_raw.tif", "_DTM.tif", dtm_raw_out)
  chm_out <- gsub("_CHM_raw.tif", "_CHM.tif", chm_raw_out)

  # Create the LAS catalog object for tiling the larger LAS file
  ctg <- readLAScatalog(y, chunk_size = 250, chunk_buffer = 0, progress = FALSE)
  opt_chunk_alignment(ctg) <- c(250, 250)
  opt_output_files(ctg) <- file.path(tile_out, "{XLEFT}_{YBOTTOM}")
  ctg_tile <- catalog_retile(ctg)
  lidR:::catalog_laxindex(ctg_tile)

  # The point clouds provided have been classifed already, so first just
  # classify noise, and then filter out the noise using the triangulation stage,
  # then produce the DTM and CHM which would use the filtered point cloud
  # classified already, so just produce the DTM from those classified point clouds
  ivf_pipe <- classify_with_ivf()
  tin_pipe <- triangulate(
    filter = "-keep_class 2 9 -drop_class 18 -drop_z_below 0", ofile = ""
  )
  dtm_pipe <- lasR::rasterize(res = rres, tin_pipe, ofile = dtm_raw_out)
  norm_pipe <- transform_with(tin_pipe)
  chm_pipe <- lasR::rasterize(
    res = rres, operators = "max", filter = "-drop_z_below 0", ofile = ""
  )
  pf_pipe <- pit_fill(chm_pipe, ofile = chm_raw_out)
  pipeline <- ivf_pipe + tin_pipe + dtm_pipe + norm_pipe + chm_pipe + pf_pipe
  set_parallel_strategy(nested(ncores() %/% 4L, 4L))
  dtm_chm_raw <- exec(pipeline, on = tile_out, progress = TRUE)
  dtm_chm_raw <- c(dtm_chm_raw[[1]], dtm_chm_raw[[2]])
  names(dtm_chm_raw) <- paste0(
    strsplit(basename(dirname(y)), "_")[[1]][1], c("_DTM", "_CHM")
  )

  # Mask the CHM and DTM to the flight area provided by the KML files
  kml <- suppressWarnings(vect(kml_file, what = "geoms")) %>%
    project(terra::crs(dtm_chm_raw))
  dtm_chm <- mask(dtm_chm_raw, kml) %>%
    writeRaster(
      filename = c(dtm_out, chm_out), overwrite = TRUE,
      names = names(.)
    )
})

# Cleanup
raw_dtms <- list.files(dtm_dir,
  pattern = "_DTM_raw.tif$|_CHM_raw.tif$",
  full.names = TRUE
)
unlink(c(raw_dtms, tile_dir), recursive = TRUE)
rm(raw_dtms, tile_dir)

```

## DTM and CHM merge

Next, mosaic the DTM and CHM images together. We make use of a "match" parameter in SAGA GIS's `mosaic` function for the DTM which ultimately smooths the DTM between adjacent flight areas. This parameter is not used in other mosaicking tasks carried out in this project.

```{r DTM_Mosaic, include=FALSE}

# Define input file lists, and then mosaic
dtm_chm_list <- do.call(c, lapply(las_proc, sources))
dtm_chm_mos <- do.call(c, lapply(c("DTM", "CHM"), function(x) {
  # Write a list of tif files in a text file to be read by SAGA GIS for mosaicking
  file_list <- grep(paste0("_", x, ".tif$"), dtm_chm_list, value = TRUE)
  write(file_list, file = file.path(tempdir(), paste0(x, "_file_list.txt")))
  rast_mosaic <- saga$grid_tools$mosaicking(
    target_out_grid = file.path(layr_dir, paste0(x, ".tif")),
    target_definition = 1,
    target_template = aoi_r,
    file_list = file.path(tempdir(), paste0(x, "_file_list.txt")),
    overlap = 5,
    blend_dist = 15,
    blend_bnd = 0,
    match = ifelse(x == "DTM", 3, 0)
  )

  return(rast_mosaic)
}))

```

## Climate based layers

As of later 2024, a new `ClimateNAr` package has been developed that does not require ClimateBC/ClimateNA be downloaded to your computer. Instead, the R package is hosted on a private repository where the developers have control over the file size of the package, meaning that they can store a bunch of the required data in the package itself instead of needing to link it to another downloaded folder. Instructions for downloading and installing this package are listed in the "00_install.R" file. This also might have made the function usable across other OS's, which was not the case before.

It is quicker and more memory efficient to generate climate layers by flight area, and then mosaic each climate layer together at the end rather than trying to generate the climate layers for the entire area in a single function. For this, we rely on the original DTM's before they were mosaicked. These original DTM's get thrown into a parallelized loop to take advantage of the amount of cores that your PC has, with the drawback being memory: the `ClimateNAr()` function requires a lot of memory on each loaded core, so we can't make full use of the processor potential without running out of memory. Tune core usage as needed.

```{r Climate_attributes, include=FALSE}

# Get the input list of DTM's, then define the period list of periods from which
# climate data will be generated, and a variable list for which variables to
# generate. Summer based variables from 2023 were generated for this project
# to attempt to closely match the weather conditions from the flights conducted.

dtm_df <- data.frame(
  dtm = list.files(dtm_dir, pattern = "_DTM.tif$", full.names = TRUE)
) %>%
  mutate(flight = sapply(
    strsplit(basename(dtm), "_"), function(x) x[-length(x)]
  )) %>%
  left_join(rgb_df, by = "flight")
pl <- c("Year_2023.ann")
vl <- paste0(c(
  "Tave", "Tmax", "Tmin", "PPT", "Rad", "DD_0", "DD5", "DD_18", "DD18", "DD1040",
  "NFFD", "PAS", "Eref", "CMD", "RH", "CMI"
), "_sm")

# Create a variable indicating which variables are integer types
int_ids <- paste0(c(
  "PPT", "DD_0", "DD5", "DD_18", "DD18", "DD1040", "NFFD", "PAS", "Eref", "CMD",
  "RH"
), "_sm")

# Generate climate variables by flight area. This will save memory and time
# compared to generating climate variables for the entire area.
plan(multisession, workers = ncores() %/% 6)
clm_par <- future_lapply(seq_len(nrow(dtm_df)), function(x) {
  y <- pull(dtm_df, dtm)[x]
  clm_subdir <- file.path(clm_dir, gsub(".tif", "", basename(y)))
  dir.create(clm_subdir, showWarnings = FALSE)

  kml_file <- pull(dtm_df, kml)[x]

  # First, project DTM to required lat/long format
  dtm_bca <- rast(y)
  dtm_wgs <- dtm_bca %>%
    project("EPSG:4326", threads = FALSE, filename = file.path(
      tempdir(), basename(y)
    ), overwrite = TRUE)

  # Set input and output paths. Output path must include trailing "/".
  # The outputs will be in Lat/Long, so save to temporary directory first.
  dtm_in <- sources(dtm_wgs)
  clm_dest <- file.path(tempdir(), "ClimateBC_Layers", "/")
  dir.create(clm_dest, showWarnings = FALSE)

  # Run the function to generate desired climate variables. This will take some
  # time, but will generate .tif files for each variable it outputs.
  clm <- climateNAr(dtm_in, periodList = pl, varList = vl, outDir = clm_dest)
  clm <- rast(list.files(paste0(clm_dest, gsub(".tif", "", basename(dtm_in))),
    recursive = TRUE, pattern = ".tif$", full.names = TRUE
  ))

  # Reprojection and masking: don't save outputs here, keep these in memory!
  # Select and reproject integer based layers back to the base DEM extent and
  # resolution using the nearest neighbour method
  kml <- suppressWarnings(vect(kml_file, what = "geoms")) %>%
    project(terra::crs(dtm_bca))

  clm_int <- clm[[which(names(clm) %in% int_ids)]]
  clm_int_bca <- project(
    clm_int, dtm_bca,
    threads = FALSE, method = "near"
  ) %>%
    mask(kml)

  # Select and reproject numeric based layers back to the base DEM extent and
  # resolution using the bilnear interpolation method
  clm_num <- clm[[which(!names(clm) %in% int_ids)]]
  clm_num_bca <- project(
    clm_num, dtm_bca,
    threads = FALSE, method = "bilinear"
  ) %>%
    mask(kml)

  # Ideally, the objects above are stored in memory. Give the SpatRaster layers
  # more descriptive names.
  names(clm_int_bca) <- paste0(
    "Climate_", basename(dirname(sources(clm_int))), "_",
    gsub(".tif", "", basename(sources(clm_int)))
  )
  names(clm_num_bca) <- paste0(
    "Climate_", basename(dirname(sources(clm_num))), "_",
    gsub(".tif", "", basename(sources(clm_num)))
  )

  # Write each raster out to the climate variable folder and subfolder. Again,
  # hopefully this is all done in memory to save time when writing each raster
  # to a file.
  clm_int_bca <- writeRaster(clm_int_bca, file.path(
    clm_subdir, paste0(names(clm_int_bca), ".tif")
  ),
  datatype = "INT2S", overwrite = TRUE
  )
  clm_num_bca <- writeRaster(clm_num_bca, file.path(
    clm_subdir, paste0(names(clm_num_bca), ".tif")
  ),
  datatype = "FLT4S", overwrite = TRUE
  )

  # Clean up files, return file list (required for future_lapply function)
  unlink(sources(clm))
  rm(clm)
  gc()
  return(sources(c(clm_int_bca, clm_num_bca)))
}, future.seed = NULL)
plan(sequential)
clm_par <- lapply(clm_par, rast)

# Mosaic the climate layers together, following each layers respective resampling
# strategy
clm_mosaics <- do.call(c, lapply(names(clm_par[[1]]), function(x) {
  # Get every one of the rasters based on file names
  clm_var <- lapply(clm_par, "[[", x)

  # Change resampling strategy for mosaicking based on data type
  rsmp <- ifelse(datatype(clm_var[[1]]) == "INT2S", 1, 3)

  # Generate list of variables from the clm_var object, and write this as a
  # text file for SAGA GIS.
  clm_list <- sapply(clm_var, sources, USE.NAMES = FALSE)
  write(clm_list, file = file.path(tempdir(), paste0(x, "_file_list.txt")))
  clm_mosaic <- saga$grid_tools$mosaicking(
    target_out_grid = file.path(layr_dir, paste0(x, ".tif")),
    file_list = file.path(tempdir(), paste0(x, "_file_list.txt")),
    target_definition = 1,
    target_template = aoi_r,
    resampling = rsmp,
    overlap = 5,
    blend_dist = 15,
    blend_bnd = 0,
    match = 0
  )

  return(clm_mosaic)
}))

# Cleanup
unlink(c(dtm_dir, clm_dir), recursive = TRUE)
rm(dtm_dir, clm_dir)

```

## Multispectral indices

Multispectral indices are generated from reflectance layers (i.e.: blue, green, red, NIR, and red-edge bands). There are many different indices that may be generated from these bands, and those are calculated using the `spectralIndices()` function in the `rstoolbox` package. Ultimately, we want these indices to match the resolution and extent of the mosaicked DTM, so first each band for each flight area needs to be resampled to a lower resolution (0.5m\^2). Once resampled, the bands can be mosaicked together (e.g.: all blue bands in a single raster image). Finally, once all bands are generated, the spectral indices may be generated.

```{r MS_Indices, include=FALSE}

# Could potentially be in future_lapply loop instead.
plan(multisession, workers = ncores() %/% 2)
ms_lowres <- future_lapply(seq_len(nrow(ms_df)), function(x) {
  # Define inputs and outputs
  y <- pull(ms_df, ms)[x]
  flight_id <- pull(ms_df, flight)[x]
  kml_file <- pull(ms_df, kml)[x]
  r_files <- list.files(y, pattern = ".tif$", full.names = TRUE)
  r_files <- grep("_lwir.tif$", r_files, value = TRUE, invert = TRUE)
  r <- rast(r_files)

  # The names that are created from the reflectance directories are too long;
  # rename these layers so that they are more simply their band ID's
  r_names <- strsplit(names(r), "_")
  r_names <- sapply(r_names, function(y) y[length(y)])
  names(r) <- r_names

  # Create output directory for the flight, and a dummy raster which will be
  # used to downsample the reflectance layers to
  r_out_dir <- file.path(ms_dir, flight_id)
  r_out <- file.path(r_out_dir, paste0(r_names, ".tif"))
  dir.create(r_out_dir, showWarnings = FALSE)
  kml <- suppressWarnings(vect(kml_file, what = "geoms")) %>%
    project(terra::crs(r))
  dummy <- rast(ext(r), crs = terra::crs(r), res = rres)

  # Resample to lower resolution using the "cubicspline" method, then mask the
  # raster to the flight area, then write each layer to its own file
  rr <- resample(r, dummy, method = "cubicspline", threads = FALSE) %>%
    mask(kml) %>%
    writeRaster(r_out, overwrite = TRUE)
  return(sources(rr))
}, future.seed = NULL)
plan(sequential)
ms_lowres <- lapply(ms_lowres, rast)

# Mosaic each band together
bands_mos <- do.call(c, lapply(names(ms_lowres[[1]]), function(x) {
  # Create the output file path for the merged bands
  band_out <- file.path(ms_dir, "Bands")
  dir.create(band_out, showWarnings = FALSE)

  # Get each of the rasters based on the layer name (e.g.: all blue rasters)
  band <- lapply(ms_lowres, "[[", x)

  # Generate the list of files that will be mosaicked and write them to a text
  # file for SAGA GIS to use.
  band_list <- sapply(band, sources, USE.NAMES = FALSE)
  write(band_list, file = file.path(tempdir(), paste0(x, "_file_list.txt")))
  band_mosaic <- saga$grid_tools$mosaicking(
    target_out_grid = file.path(band_out, paste0(x, ".tif")),
    file_list = file.path(tempdir(), paste0(x, "_file_list.txt")),
    target_definition = 1,
    target_template = aoi_r,
    overlap = 5,
    blend_dist = 15,
    blend_bnd = 0,
    match = 0
  )

  return(band_mosaic)
}))

# Generate spectral indices
s <- spectralIndices(
  img = bands_mos, blue = "blue", green = "green", red = "red", nir = "nir",
  redEdge2 = "red edge"
) %>%
  writeRaster(file.path(layr_dir, paste0("MS_", names(.), ".tif")),
    overwrite = TRUE
  )

# Cleanup
unlink(ms_dir, recursive = TRUE)
rm(ms_dir)

```

## Terrain layers

Finally, create terrain layers from the mosaicked DTM. The variables generated include the ones from the basic terrain analysis, as well as a number of variables which are included in a toolchain provided from an XML file that I wrote.

```{r Terrain_attributes, include=FALSE}

dtm <- rast(file.path(layr_dir, "DTM.tif"))
mrvbf_param <- mrvbf_threshold(xres(dtm))
od <- normalizePath(file.path(layr_dir, "Terrain_"), mustWork = FALSE)

# Use a built in toolchain to get some of the terrain layers
ta_basic <- saga$ta_compound$basic_terrain_analysis(
  elevation = dtm,
  threshold = 7,
  sinks = file.path(tempdir(), "sinks.tif"),
  slope = paste0(od, "slope.tif"),
  aspect = paste0(od, "aspect.tif"),
  hcurv = paste0(od, "hcurv.tif"),
  vcurv = paste0(od, "vcurv.tif"),
  convergence = paste0(od, "convergence.tif"),
  flow = paste0(od, "tca.tif"),
  wetness = paste0(od, "twi.tif"),
  lsfactor = paste0(od, "ls_factor.tif"),
  chnl_base = paste0(od, "chnl_base.tif"),
  chnl_dist = paste0(od, "chnl_dist.tif"),
  vall_depth = paste0(od, "valley_depth.tif"),
  rsp = paste0(od, "relative_slope_position.tif"),
  .verbose = TRUE
)
ta_basic <- do.call(c, unname(ta_basic))
dtmp <- sum(dtm, ta_basic[["sinks"]],
  na.rm = TRUE,
  filename = file.path(tempdir(), "DTM-preproc.tif"),
  overwrite = TRUE, wopt = list(names = "DTM-preproc")
)
ta_basic <- ta_basic[[-which(names(ta_basic) == "sinks")]]

# Use custom made toolchain to get more terrain layers:
ta_custom <- saga$ta_morphometry$custom_toolchain(
  dem = dtmp, t_slope = mrvbf_param,
  mrvbf = paste0(od, "mrvbf.tif"),
  mrrtf = paste0(od, "mrrtf.tif"),
  dah = paste0(od, "dah.tif"),
  tpi = paste0(od, "tpi.tif"),
  tri = paste0(od, "tri.tif"),
  pos = paste0(od, "openness_pos.tif"),
  neg = paste0(od, "openness_neg.tif"),
  direct = paste0(od, "insolation_direct.tif"),
  diffuse = paste0(od, "insolation_diffuse.tif"),
  location = 1, period = 2, day = "2024-07-30", day_stop = "2024-10-08",
  days_step = 14, .verbose = TRUE
)
ta_custom <- do.call(c, unname(ta_custom))

# Sanity check for ensuring things line up properly:
covs <- c(dtm_chm_mos, clm_mosaics, s, ta_basic, ta_custom)
covs_files <- rast(list.files(layr_dir, pattern = ".tif", full.names = TRUE))

# Cleanup
saga_remove_tmpfiles()
unlink(file.path(tempdir(), c("sinks.tif", "DTM-preproc.tif")))

```